{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing from all possible events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 48 events (all good), 3 – 6 s (baseline off), ~6.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12\n",
      " 'feet': 12\n",
      " 'tongue': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/torch/nn/functional.py:1545: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 1.3876 | Train Acc: 23.91% | Val Loss: 1.3827 | Val Acc: 21.74%\n",
      "Epoch 2/50 - Train Loss: 1.3895 | Train Acc: 22.55% | Val Loss: 1.3834 | Val Acc: 25.00%\n",
      "Epoch 3/50 - Train Loss: 1.3920 | Train Acc: 25.00% | Val Loss: 1.3836 | Val Acc: 28.26%\n",
      "Epoch 4/50 - Train Loss: 1.3883 | Train Acc: 26.36% | Val Loss: 1.3833 | Val Acc: 26.09%\n",
      "Epoch 5/50 - Train Loss: 1.3879 | Train Acc: 25.82% | Val Loss: 1.3842 | Val Acc: 25.00%\n",
      "Epoch 6/50 - Train Loss: 1.3904 | Train Acc: 24.73% | Val Loss: 1.3844 | Val Acc: 21.74%\n",
      "Early stopping triggered.\n",
      "Evaluating on test set...\n",
      "Subject 1 - Test Loss: 1.3875  |  Test Acc: 30.17%\n",
      "Final test accuracy for subject 1: 30.17%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from moabb.datasets import BNCI2014_001  # [1]\n",
    "from moabb.paradigms import MotorImagery  # [1]\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "############################################################\n",
    "# 1) DATA LOADING AND PRE-PROCESSING\n",
    "############################################################\n",
    "\n",
    "def load_moabb_data(subject_id=1, fmin=8.0, fmax=30.0, tmin=1.0, tmax=4.0):\n",
    "    \"\"\"\n",
    "    Load data from BNCI2014_001 using the moabb library. \n",
    "    Return the EEG trials (X) and class labels (y) after basic pre-processing.\n",
    "    We apply a band-pass filter from fmin to fmax and extract the time segment \n",
    "    between tmin and tmax relative to the trial onset[1].\n",
    "    \"\"\"\n",
    "    dataset = BNCI2014_001()  # [1]\n",
    "    paradigm = MotorImagery(n_classes=2, fmin=fmin, fmax=fmax, tmin=tmin, tmax=tmax)\n",
    "    X_list, labels, meta = paradigm.get_data(dataset=dataset, subjects=[subject_id])\n",
    "    \n",
    "    # Convert list of arrays into a single numpy array of shape (trials, time_points, channels)\n",
    "    # The original shape is (channels, time), so we transpose to get (time, channels).\n",
    "    X_np = []\n",
    "    for arr in X_list:\n",
    "        X_np.append(arr.transpose(1,0))\n",
    "    X_np = np.stack(X_np, axis=0)\n",
    "    \n",
    "    # Encode labels numerically\n",
    "    le = LabelEncoder()\n",
    "    y_np = le.fit_transform(labels)\n",
    "    return X_np, y_np\n",
    "    \n",
    "def split_and_augment_data(X, y, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Split data into training and test sets, optionally apply SMOTE \n",
    "    to handle class imbalance in the training set.\n",
    "    \"\"\"\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_ratio, shuffle=True, random_state=SEED, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Reshape for SMOTE - SMOTE requires 2D arrays\n",
    "    n_samples, t_points, n_ch = X_train.shape\n",
    "    X_train_2d = X_train.reshape(n_samples, -1)\n",
    "    \n",
    "    # Apply SMOTE for data augmentation\n",
    "    smote = SMOTE(random_state=SEED)\n",
    "    X_train_bal, y_train_bal = smote.fit_resample(X_train_2d, y_train)\n",
    "    \n",
    "    # Reshape back to (samples, time_points, channels)\n",
    "    X_train_bal = X_train_bal.reshape(X_train_bal.shape[0], t_points, n_ch)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_torch = torch.tensor(X_train_bal, dtype=torch.float32)\n",
    "    y_train_torch = torch.tensor(y_train_bal, dtype=torch.long)\n",
    "    X_test_torch  = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_torch  = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    return X_train_torch, y_train_torch, X_test_torch, y_test_torch\n",
    "\n",
    "############################################################\n",
    "# 2) BUILD A 1D-CNN MODEL IN PYTORCH\n",
    "############################################################\n",
    "\n",
    "class OneDCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A 1D CNN model inspired by the referenced architecture[1].\n",
    "    Convolves along the time axis while treating channels as a feature dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(OneDCNN, self).__init__()\n",
    "        \n",
    "        # (batch, time, channels) => reshape or permute needed in forward\n",
    "        # Convolution blocks\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=32, kernel_size=8, padding=4)\n",
    "        self.bn1   = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=8, padding=0)\n",
    "        self.bn2   = nn.BatchNorm1d(32)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)  # SpatialDropout alternative: Dropout2d on channels\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=6, padding=0)\n",
    "        self.avgpool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=6, padding=0)\n",
    "        self.drop4 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # We'll flatten after conv4. The exact dimension depends on input size.\n",
    "        # We'll compute it dynamically in forward if needed.\n",
    "        self.fc1 = nn.Linear(32*something_placeholder(160, 4), 296)  # We'll fix the dimension after we see an example\n",
    "        self.fc2 = nn.Linear(296, 148)\n",
    "        self.fc3 = nn.Linear(148, 74)\n",
    "        self.fc4 = nn.Linear(74, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, channels) => permute to (batch, channels, time)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.avgpool3(x)\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "def compute_flatten_size(model, num_channels, time_dim=640):\n",
    "    \"\"\"\n",
    "    Utility to compute the flatten dimension after the last convolution, \n",
    "    for a given input size. We can forward a dummy batch to do so.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.zeros(1, time_dim, num_channels)\n",
    "        out = model(dummy)\n",
    "        return out.shape[1]\n",
    "\n",
    "class OneDCNNFlexible(nn.Module):\n",
    "    \"\"\"\n",
    "    Similar model, but we dynamically fix the FC layer sizes after we see \n",
    "    the flattened dimension from the conv blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(OneDCNNFlexible, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(num_channels, 32, 8, padding=4)\n",
    "        self.bn1   = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 32, 8, padding=0)\n",
    "        self.bn2   = nn.BatchNorm1d(32)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 32, 6, padding=0)\n",
    "        self.avgpool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(32, 32, 6, padding=0)\n",
    "        self.drop4 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        # We will define fc layers in a separate method once we know flatten size\n",
    "        self.flatten_size = None\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        self.fc3 = None\n",
    "        self.fc4 = None\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        # x: (batch, time, channels) => permute to (batch, channels, time)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.avgpool3(x)\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Initialize FC layers if not done yet\n",
    "        if self.fc1 is None:\n",
    "            in_feats = x.shape[1]\n",
    "            self.fc1 = nn.Linear(in_feats, 296)\n",
    "            self.fc2 = nn.Linear(296, 148)\n",
    "            self.fc3 = nn.Linear(148, 74)\n",
    "            self.fc4 = nn.Linear(74, self.num_classes)\n",
    "            # Move them to same device\n",
    "            self.fc1.to(x.device)\n",
    "            self.fc2.to(x.device)\n",
    "            self.fc3.to(x.device)\n",
    "            self.fc4.to(x.device)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "############################################################\n",
    "# 3) TRAINING UTILITIES (EARLY STOPPING, TRAIN/EVAL LOOP)\n",
    "############################################################\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve \n",
    "    after a given patience.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=1e-4):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_val_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_val_loss is None:\n",
    "            self.best_val_loss = val_loss\n",
    "        elif val_loss > (self.best_val_loss - self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-3, patience=5, device='cpu'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    early_stopper = EarlyStopping(patience=patience, min_delta=1e-4)\n",
    "    \n",
    "    best_model_state = None\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_correct, total = 0.0, 0, 0\n",
    "        \n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * Xb.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            train_correct += (preds == yb).sum().item()\n",
    "            total += Xb.size(0)\n",
    "        \n",
    "        train_loss /= total\n",
    "        train_acc = 100.0 * train_correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv, yv = Xv.to(device), yv.to(device)\n",
    "                out_v = model(Xv)\n",
    "                loss_v = criterion(out_v, yv)\n",
    "                \n",
    "                val_loss += loss_v.item() * Xv.size(0)\n",
    "                preds_v = out_v.argmax(dim=1)\n",
    "                val_correct += (preds_v == yv).sum().item()\n",
    "                val_total += Xv.size(0)\n",
    "        val_loss /= val_total\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        \n",
    "        # Print epoch info\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopper(val_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    # Load best model weights\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            out = model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            test_loss += loss.item() * Xb.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += Xb.size(0)\n",
    "            \n",
    "    avg_loss = test_loss / total\n",
    "    acc = 100.0 * correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "############################################################\n",
    "# 4) MAIN EXPERIMENT PIPELINE\n",
    "############################################################\n",
    "\n",
    "def run_experiment(subject_id=1, batch_size=16, device='cpu'):\n",
    "    # Load data\n",
    "    print(f\"Loading data for subject {subject_id}...\")\n",
    "    X, y = load_moabb_data(subject_id=subject_id, fmin=8, fmax=30, tmin=1, tmax=4)\n",
    "    \n",
    "    # Split + SMOTE\n",
    "    X_train, y_train, X_test, y_test = split_and_augment_data(X, y, test_ratio=0.2)\n",
    "    \n",
    "    # Further split train => train/val\n",
    "    val_ratio = 0.2\n",
    "    n_train = int((1 - val_ratio) * X_train.shape[0])\n",
    "    n_val   = X_train.shape[0] - n_train\n",
    "    \n",
    "    train_ds, val_ds = random_split(\n",
    "        TensorDataset(X_train, y_train),\n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(SEED)\n",
    "    )\n",
    "    \n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    num_channels = X.shape[2]\n",
    "    \n",
    "    # Build model (use the flexible approach so we don't worry about layer shapes)\n",
    "    model = OneDCNNFlexible(num_channels=num_channels, num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Train\n",
    "    print(\"Starting training...\")\n",
    "    model = train_model(model, train_loader, val_loader, epochs=50, lr=1e-3, patience=5, device=device)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Evaluating on test set...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, device=device)\n",
    "    print(f\"Subject {subject_id} - Test Loss: {test_loss:.4f}  |  Test Acc: {test_acc:.2f}%\")\n",
    "    return model, (test_loss, test_acc)\n",
    "\n",
    "def main():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    subject_id = 1  # Example single-subject\n",
    "    model, results = run_experiment(subject_id=subject_id, device=device)\n",
    "    print(f\"Final test accuracy for subject {subject_id}: {results[1]:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
