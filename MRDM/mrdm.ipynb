{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery, LeftRightImagery\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from mne.decoding import CSP\n",
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from pyriemann.utils.mean import mean_riemann\n",
    "from pyriemann.utils.distance import distance_riemann\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Define a causal bandpass filter function using a Butterworth design.\n",
    "def causal_bandpass_filter(data, lowcut=8, highcut=30, fs=250, order=50):\n",
    "    nyq = 0.5 * fs\n",
    "    # Normalize the cutoff frequencies (Matlab's fir1 expects normalized cutoff frequencies\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Design the FIR filter. Note: order+1 coefficients are returned to match Matlab's fir1 which returns n+1 taps.\n",
    "    b = signal.firwin(order + 1, [low, high], window='hamming', pass_zero=False)\n",
    "    # Apply the filter causally using lfilter (this introduces a constant delay).\n",
    "    filtered_data = signal.lfilter(b, [1.0], data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the data directory where your GDF files are stored.\n",
    "data_dir = '/home/vishwa/eeg_tl/Recreating papers/BCICIV_2a'  # Replace with your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_all_event_ids = {'769': 769, '770': 770, '771': 771, '772': 772}\n",
    "active_lr_event_ids = {'769': 769, '770': 770}\n",
    "unknown_event_id = {'783': 783} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a sampling frequency of 250 Hz, 1001 samples equate to 1001/250 seconds.\n",
    "sfreq = 250\n",
    "tmin = 0.5       # Epoch start at cue onset.\n",
    "# Set tmax so that n_samples = (tmax-tmin)*sfreq + 1 = 1001, i.e. 4 seconds long.\n",
    "tmax = 2.5  # This gives 4.0 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 1: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 2: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 3: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 4: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 5: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 6: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 7: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 8: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 9: Epoch data shape (288, 22, 501)\n",
      "Loaded data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "train_active_X = []         # List to hold numpy arrays with shape (n_trials, 22, 1001) per subject.\n",
    "train_active_y = []         # List to hold event labels per subject.\n",
    "train_active_metadata = []  # List to hold event metadata per subject.\n",
    "\n",
    "# Loop over subjects. Assume files are named \"A01T.gdf\", \"A02T.gdf\", ..., \"A09T.gdf\".\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}T.gdf')\n",
    "    \n",
    "    # Read the GDF file (using preload=True to load data into memory).\n",
    "    train_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    # Retain only EEG channels (22 channels) and exclude EOG channels.\n",
    "    train_raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract events corresponding only to the four desired types.\n",
    "    train_active_events, _ = mne.events_from_annotations(train_raw, event_id=active_all_event_ids)\n",
    "    \n",
    "    # Create epochs from tmin to tmax.\n",
    "    train_active_epochs = mne.Epochs(train_raw, train_active_events, event_id=active_all_event_ids, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Get the epoch data (num_epochs x 22 channels x 1001 samples).\n",
    "    train_active_data = train_active_epochs.get_data()\n",
    "    \n",
    "    # Print the number of extracted epochs to verify\n",
    "    print(f\"Subject {subj}: Epoch data shape {train_active_data.shape}\")\n",
    "    \n",
    "    # Sampling frequency from raw.info (should be 250).\n",
    "    fs = int(train_raw.info['sfreq'])\n",
    "    # print(fs)\n",
    "    n_trials, n_channels, n_times = train_active_data.shape\n",
    "    train_active_filtered_data = np.empty_like(train_active_data)\n",
    "    \n",
    "    # Apply the causal bandpass filter channel‐wise for each trial.\n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            train_active_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                train_active_data[trial, ch, :],\n",
    "                lowcut=8,    # Lower bound of sensorimotor rhythm.\n",
    "                highcut=30,  # Upper bound of sensorimotor rhythm.\n",
    "                fs=fs,\n",
    "                order=50     # Lower order for a smoother causal filter.\n",
    "            )\n",
    "    \n",
    "    # Append the processed data, labels, and event metadata.\n",
    "    train_active_X.append(train_active_filtered_data)\n",
    "    train_active_y.append(train_active_epochs.events[:, 2])  # The third column holds the event code.\n",
    "    train_active_metadata.append(train_active_epochs.events)\n",
    "\n",
    "print(\"Loaded data for\", len(train_active_X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 1: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 2: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 3: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 4: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 5: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 6: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 7: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 8: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 9: Epoch data shape (288, 22, 501)\n",
      "Loaded data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "eval_active_X = []         \n",
    "eval_active_y = []        \n",
    "eval_active_metadata = [] \n",
    "\n",
    "# Loop over subjects. Assume files are named \"A01T.gdf\", \"A02T.gdf\", ..., \"A09T.gdf\".\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}E.gdf')\n",
    "    mat_data = loadmat(f'/home/vishwa/eeg_tl/Recreating papers/BCICIV_2A true labels/A{subj:02d}E.mat')\n",
    "    true_y =  np.array(mat_data['classlabel'], dtype=np.int64).reshape(288,) + 768\n",
    "    # Read the GDF file (using preload=True to load data into memory).\n",
    "    eval_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    # Retain only EEG channels (22 channels) and exclude EOG channels.\n",
    "    eval_raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract events corresponding only to the four desired types.\n",
    "    eval_active_events, _ = mne.events_from_annotations(eval_raw, event_id=unknown_event_id)\n",
    "    \n",
    "    # Create epochs from tmin to tmax.\n",
    "    eval_active_epochs = mne.Epochs(eval_raw, eval_active_events, event_id=unknown_event_id, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Get the epoch data (num_epochs x 22 channels x 1001 samples).\n",
    "    eval_active_data = eval_active_epochs.get_data()\n",
    "    \n",
    "    # Print the number of extracted epochs to verify\n",
    "    print(f\"Subject {subj}: Epoch data shape {eval_active_data.shape}\")\n",
    "    \n",
    "    # Sampling frequency from raw.info (should be 250).\n",
    "    fs = int(eval_raw.info['sfreq'])\n",
    "    # print(fs)\n",
    "    n_trials, n_channels, n_times = eval_active_data.shape\n",
    "    eval_active_filtered_data = np.empty_like(eval_active_data)\n",
    "    \n",
    "    # Apply the causal bandpass filter channel‐wise for each trial.\n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            eval_active_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                eval_active_data[trial, ch, :],\n",
    "                lowcut=8,    # Lower bound of sensorimotor rhythm.\n",
    "                highcut=30,  # Upper bound of sensorimotor rhythm.\n",
    "                fs=fs,\n",
    "                order=50     # Lower order for a smoother causal filter.\n",
    "            )\n",
    "    \n",
    "    # Append the processed data, labels, and event metadata.\n",
    "    eval_active_X.append(eval_active_filtered_data)\n",
    "    eval_active_y.append(true_y)  # The third column holds the event code.\n",
    "    eval_active_metadata.append(eval_active_epochs.events)\n",
    "\n",
    "print(\"Loaded data for\", len(eval_active_X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_active_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 501)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_active_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_active_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_active_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have similar variables for eval data:\n",
    "# eval_active_X and eval_active_y\n",
    "\n",
    "# Initialize lists to store concatenated data\n",
    "concatenated_X = []\n",
    "concatenated_y = []\n",
    "\n",
    "# Loop through each subject\n",
    "for subject in range(9):\n",
    "    # Concatenate X data for current subject\n",
    "    subject_X = np.concatenate([\n",
    "        train_active_X[subject],\n",
    "        eval_active_X[subject]\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Concatenate y data for current subject\n",
    "    subject_y = np.concatenate([\n",
    "        train_active_y[subject],\n",
    "        eval_active_y[subject]\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Append to lists\n",
    "    concatenated_X.append(subject_X)\n",
    "    concatenated_y.append(subject_y)\n",
    "\n",
    "# Convert lists to arrays if needed\n",
    "concatenated_X = np.array(concatenated_X)\n",
    "concatenated_y = np.array(concatenated_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(X):\n",
    "    covs = np.array([trial @ trial.T for trial in X])\n",
    "    return covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = cov(concatenated_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "print(covs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs_labels = concatenated_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576,)\n"
     ]
    }
   ],
   "source": [
    "print(covs_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([769, 770, 771, 772])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(covs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance_classifier(train_covs, train_labels, test_cov):\n",
    "    \"\"\"\n",
    "    Implementation of Minimum Distance to Riemannian Mean classifier\n",
    "    \"\"\"\n",
    "    classes = np.unique(train_labels)\n",
    "    distances = np.zeros(len(classes))\n",
    "    \n",
    "    # Compute class-wise Riemannian means\n",
    "    class_means = {}\n",
    "    for i, k in enumerate(classes):  # Use enumerate to get index\n",
    "        idx = train_labels == k\n",
    "        class_means[k] = mean_riemann(train_covs[idx])\n",
    "    \n",
    "    # Compute distances to each class mean\n",
    "    for i, k in enumerate(classes):  # Use enumerate to get index\n",
    "        distances[i] = distance_riemann(test_cov, class_means[k])\n",
    "    \n",
    "    return classes[np.argmin(distances)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate_subject(subject_data, subject_labels, n_folds=30):\n",
    "    \"\"\"\n",
    "    Perform 30-fold cross validation for a single subject\n",
    "    \n",
    "    Parameters:\n",
    "    subject_data: array of shape (288, 22, 1001)\n",
    "    subject_labels: array of shape (288,)\n",
    "    \"\"\"\n",
    "    # First compute covariance matrices for all trials\n",
    "    covs = cov(subject_data)\n",
    "    # Initialize K-fold\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store accuracies for each fold\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    # Perform cross validation\n",
    "    for fold_idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(covs))):\n",
    "        # Split data into train and test\n",
    "        train_covs = covs[train_idx]\n",
    "        train_labels = subject_labels[train_idx]\n",
    "        test_covs = covs[test_idx]\n",
    "        test_labels = subject_labels[test_idx]\n",
    "        \n",
    "        # Predict each test trial\n",
    "        predictions = []\n",
    "        for test_cov in test_covs:\n",
    "            pred = minimum_distance_classifier(train_covs, train_labels, test_cov)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = np.mean(np.array(predictions) == test_labels)\n",
    "        fold_accuracies.append(accuracy)\n",
    "    \n",
    "    return fold_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_accuracies = cross_validate_subject(covs, covs_labels)\n",
    "# print(np.mean(subject_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [03:15,  6.52s/it]\n",
      "30it [03:40,  7.34s/it]\n",
      "30it [03:26,  6.88s/it]\n",
      "30it [03:31,  7.06s/it]\n",
      "30it [04:56,  9.87s/it]\n",
      "30it [04:33,  9.13s/it]\n",
      "30it [04:28,  8.95s/it]\n",
      "30it [04:28,  8.94s/it]\n",
      "30it [04:05,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy across all subjects: 0.570 ± 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run for all subjects\n",
    "all_subjects_results = []\n",
    "for subject in range(9):  # 9 subjects\n",
    "    subject_accuracies = cross_validate_subject(\n",
    "        concatenated_X[subject], \n",
    "        concatenated_y[subject]\n",
    "    )\n",
    "    all_subjects_results.append(subject_accuracies)\n",
    "\n",
    "# Calculate overall statistics\n",
    "all_subjects_results = np.array(all_subjects_results)\n",
    "mean_accuracy = np.mean(all_subjects_results)\n",
    "std_accuracy = np.std(all_subjects_results)\n",
    "\n",
    "print(f\"Mean accuracy across all subjects: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score of subj1: 0.65\n",
      "accuracy_score of subj2: 0.39\n",
      "accuracy_score of subj3: 0.74\n",
      "accuracy_score of subj4: 0.47\n",
      "accuracy_score of subj5: 0.32\n",
      "accuracy_score of subj6: 0.42\n",
      "accuracy_score of subj7: 0.65\n",
      "accuracy_score of subj8: 0.74\n",
      "accuracy_score of subj9: 0.74\n",
      "Mean accuracy from data: 0.57 ± 0.19\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_subjects_results)):\n",
    "    print(f\"accuracy_score of subj{i+1}: {np.mean(all_subjects_results[i]):.2f}\")\n",
    "print(f\"Mean accuracy from data: {mean_accuracy:.2f} ± {std_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
