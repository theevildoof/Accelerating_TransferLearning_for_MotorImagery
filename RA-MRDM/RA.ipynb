{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery, LeftRightImagery\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from mne.decoding import CSP\n",
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from pyriemann.utils.mean import mean_riemann\n",
    "from pyriemann.utils.distance import distance_riemann\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import scipy.linalg\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Define a causal bandpass filter function using a Butterworth design.\n",
    "def causal_bandpass_filter(data, lowcut=8, highcut=30, fs=250, order=50):\n",
    "    nyq = 0.5 * fs\n",
    "    # Normalize the cutoff frequencies (Matlab's fir1 expects normalized cutoff frequencies\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Design the FIR filter. Note: order+1 coefficients are returned to match Matlab's fir1 which returns n+1 taps.\n",
    "    b = signal.firwin(order + 1, [low, high], window='hamming', pass_zero=False)\n",
    "    # Apply the filter causally using lfilter (this introduces a constant delay).\n",
    "    filtered_data = signal.lfilter(b, [1.0], data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the data directory where your GDF files are stored.\n",
    "data_dir = '/home/vishwa/eeg_tl/Recreating papers/BCICIV_2a'  # Replace with your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_all_event_ids = {'769': 769, '770': 770, '771': 771, '772': 772}\n",
    "active_lr_event_ids = {'769': 769, '770': 770}\n",
    "unknown_event_id = {'783': 783} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a sampling frequency of 250 Hz, 1001 samples equate to 1001/250 seconds.\n",
    "sfreq = 250\n",
    "tmin = 0.5       # Epoch start at cue onset.\n",
    "# Set tmax so that n_samples = (tmax-tmin)*sfreq + 1 = 1001, i.e. 4 seconds long.\n",
    "tmax = 2.5  # This gives 4.0 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Eval - active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 1: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 2: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 3: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 4: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 5: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 6: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 7: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 8: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 9: Epoch data shape (288, 22, 501)\n",
      "Loaded data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "train_active_X = []         # List to hold numpy arrays with shape (n_trials, 22, 1001) per subject.\n",
    "train_active_y = []         # List to hold event labels per subject.\n",
    "train_active_metadata = []  # List to hold event metadata per subject.\n",
    "\n",
    "# Loop over subjects. Assume files are named \"A01T.gdf\", \"A02T.gdf\", ..., \"A09T.gdf\".\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}T.gdf')\n",
    "    \n",
    "    # Read the GDF file (using preload=True to load data into memory).\n",
    "    train_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    # Retain only EEG channels (22 channels) and exclude EOG channels.\n",
    "    train_raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract events corresponding only to the four desired types.\n",
    "    train_active_events, _ = mne.events_from_annotations(train_raw, event_id=active_all_event_ids)\n",
    "    \n",
    "    # Create epochs from tmin to tmax.\n",
    "    train_active_epochs = mne.Epochs(train_raw, train_active_events, event_id=active_all_event_ids, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Get the epoch data (num_epochs x 22 channels x 1001 samples).\n",
    "    train_active_data = train_active_epochs.get_data()\n",
    "    \n",
    "    # Print the number of extracted epochs to verify\n",
    "    print(f\"Subject {subj}: Epoch data shape {train_active_data.shape}\")\n",
    "    \n",
    "    # Sampling frequency from raw.info (should be 250).\n",
    "    fs = int(train_raw.info['sfreq'])\n",
    "    # print(fs)\n",
    "    n_trials, n_channels, n_times = train_active_data.shape\n",
    "    train_active_filtered_data = np.empty_like(train_active_data)\n",
    "    \n",
    "    # Apply the causal bandpass filter channel‐wise for each trial.\n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            train_active_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                train_active_data[trial, ch, :],\n",
    "                lowcut=8,    # Lower bound of sensorimotor rhythm.\n",
    "                highcut=30,  # Upper bound of sensorimotor rhythm.\n",
    "                fs=fs,\n",
    "                order=50     # Lower order for a smoother causal filter.\n",
    "            )\n",
    "    \n",
    "    # Append the processed data, labels, and event metadata.\n",
    "    train_active_X.append(train_active_filtered_data)\n",
    "    train_active_y.append(train_active_epochs.events[:, 2])  # The third column holds the event code.\n",
    "    train_active_metadata.append(train_active_epochs.events)\n",
    "\n",
    "print(\"Loaded data for\", len(train_active_X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 1: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 2: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 3: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 4: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 5: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 6: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 7: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 8: Epoch data shape (288, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 9: Epoch data shape (288, 22, 501)\n",
      "Loaded data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "eval_active_X = []         \n",
    "eval_active_y = []        \n",
    "eval_active_metadata = [] \n",
    "\n",
    "# Loop over subjects. Assume files are named \"A01T.gdf\", \"A02T.gdf\", ..., \"A09T.gdf\".\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}E.gdf')\n",
    "    mat_data = loadmat(f'/home/vishwa/eeg_tl/Recreating papers/BCICIV_2A true labels/A{subj:02d}E.mat')\n",
    "    true_y =  np.array(mat_data['classlabel'], dtype=np.int64).reshape(288,) + 768\n",
    "    # Read the GDF file (using preload=True to load data into memory).\n",
    "    eval_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    # Retain only EEG channels (22 channels) and exclude EOG channels.\n",
    "    eval_raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract events corresponding only to the four desired types.\n",
    "    eval_active_events, _ = mne.events_from_annotations(eval_raw, event_id=unknown_event_id)\n",
    "    \n",
    "    # Create epochs from tmin to tmax.\n",
    "    eval_active_epochs = mne.Epochs(eval_raw, eval_active_events, event_id=unknown_event_id, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Get the epoch data (num_epochs x 22 channels x 1001 samples).\n",
    "    eval_active_data = eval_active_epochs.get_data()\n",
    "    \n",
    "    # Print the number of extracted epochs to verify\n",
    "    print(f\"Subject {subj}: Epoch data shape {eval_active_data.shape}\")\n",
    "    \n",
    "    # Sampling frequency from raw.info (should be 250).\n",
    "    fs = int(eval_raw.info['sfreq'])\n",
    "    # print(fs)\n",
    "    n_trials, n_channels, n_times = eval_active_data.shape\n",
    "    eval_active_filtered_data = np.empty_like(eval_active_data)\n",
    "    \n",
    "    # Apply the causal bandpass filter channel‐wise for each trial.\n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            eval_active_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                eval_active_data[trial, ch, :],\n",
    "                lowcut=8,    # Lower bound of sensorimotor rhythm.\n",
    "                highcut=30,  # Upper bound of sensorimotor rhythm.\n",
    "                fs=fs,\n",
    "                order=50     # Lower order for a smoother causal filter.\n",
    "            )\n",
    "    \n",
    "    # Append the processed data, labels, and event metadata.\n",
    "    eval_active_X.append(eval_active_filtered_data)\n",
    "    eval_active_y.append(true_y)  # The third column holds the event code.\n",
    "    eval_active_metadata.append(eval_active_epochs.events)\n",
    "\n",
    "print(\"Loaded data for\", len(eval_active_X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Eval - resting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 1: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 2: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 3: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 4: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 5: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 6: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 7: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 8: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770', '771', '772']\n",
      "Subject 9: Resting data shape (287, 22, 376)\n",
      "Loaded resting data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "train_resting_X = []\n",
    "train_resting_metadata = []\n",
    "\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}T.gdf')\n",
    "    \n",
    "    # Load the GDF file and select EEG channels.\n",
    "    train_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, \n",
    "                              eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    train_raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract active events (e.g. left/right motor imagery cues).\n",
    "    train_resting_events, _ = mne.events_from_annotations(train_raw, event_id=active_all_event_ids)\n",
    "    \n",
    "    # Create active epochs.\n",
    "    train_resting_epochs = mne.Epochs(train_raw, train_resting_events, event_id=active_all_event_ids,\n",
    "                               tmin=tmin, tmax=tmax, baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Now derive resting events by shifting each active event by 6 seconds (trial end).\n",
    "    fs = int(train_raw.info['sfreq'])\n",
    "    train_resting_events[:, 0] += int(6 * fs)\n",
    "    \n",
    "    # Create resting epochs of 1.5 s duration.\n",
    "    train_resting_epochs = mne.Epochs(train_raw, train_resting_events, tmin=0, tmax=1.5,\n",
    "                                baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    train_resting_data = train_resting_epochs.get_data()\n",
    "    print(f\"Subject {subj}: Resting data shape {train_resting_data.shape}\")\n",
    "    \n",
    "    n_trials, n_channels, n_times = train_resting_data.shape\n",
    "    train_resting_filtered_data = np.empty_like(train_resting_data)\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            train_resting_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                train_resting_data[trial, ch, :],\n",
    "                lowcut=8,\n",
    "                highcut=30,\n",
    "                fs=fs,\n",
    "                order=50\n",
    "            )\n",
    "    \n",
    "    train_resting_X.append(train_resting_filtered_data)\n",
    "    train_resting_metadata.append(train_resting_epochs.events)\n",
    "\n",
    "print(\"Loaded resting data for\", len(train_resting_X), \"subjects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 1: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 2: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 3: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 4: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 5: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 6: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 7: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 8: Resting data shape (287, 22, 376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['783']\n",
      "Subject 9: Resting data shape (287, 22, 376)\n",
      "Loaded resting data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "eval_resting_X = []\n",
    "eval_resting_metadata = []\n",
    "\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}E.gdf')\n",
    "   \n",
    "    # Load the GDF file and select EEG channels.\n",
    "    eval_raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False,\n",
    "                              eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    eval_raw.pick_types(eeg=True, eog=False)\n",
    "   \n",
    "    # Extract resting events (e.g. left/right motor imagery cues).\n",
    "    eval_resting_events, _ = mne.events_from_annotations(eval_raw, event_id=unknown_event_id)\n",
    "   \n",
    "    # Create resting epochs.\n",
    "    eval_resting_epochs = mne.Epochs(eval_raw, eval_resting_events, event_id=unknown_event_id,\n",
    "                               tmin=tmin, tmax=tmax, baseline=None, preload=True, verbose=False)\n",
    "   \n",
    "    # Now derive resting events by shifting each resting event by 6 seconds (trial end).\n",
    "    fs = int(eval_raw.info['sfreq'])\n",
    "    # eval_resting_events = eval_resting_events.copy()\n",
    "    eval_resting_events[:, 0] += int(6 * fs)\n",
    "   \n",
    "    # Create resting epochs of 1.5 s duration.\n",
    "    eval_resting_epochs = mne.Epochs(eval_raw, eval_resting_events, tmin=0, tmax=1.5,\n",
    "                                baseline=None, preload=True, verbose=False)\n",
    "   \n",
    "    eval_resting_data = eval_resting_epochs.get_data()\n",
    "    print(f\"Subject {subj}: Resting data shape {eval_resting_data.shape}\")\n",
    "   \n",
    "    n_trials, n_channels, n_times = eval_resting_data.shape\n",
    "    eval_resting_filtered_data = np.empty_like(eval_resting_data)\n",
    "   \n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            eval_resting_filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                eval_resting_data[trial, ch, :],\n",
    "                lowcut=8,\n",
    "                highcut=30,\n",
    "                fs=fs,\n",
    "                order=50\n",
    "            )\n",
    "   \n",
    "    eval_resting_X.append(eval_resting_filtered_data)\n",
    "    # For resting epochs, labels might not be needed or can be set to a dummy value.\n",
    "    eval_resting_metadata.append(eval_resting_epochs.events)\n",
    "\n",
    "\n",
    "print(\"Loaded resting data for\", len(eval_resting_X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cov + Affine transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(X):\n",
    "    covs = np.array([trial @ trial.T for trial in X])\n",
    "    return covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_active_covs = [cov(i) for i in train_active_X]\n",
    "eval_active_covs = [cov(i) for i in eval_active_X]\n",
    "\n",
    "train_resting_covs = [cov(i) for i in train_resting_X]\n",
    "eval_resting_covs =  [cov(i) for i in eval_resting_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resting_covs_mean = [mean_riemann(i) for i in train_resting_covs]\n",
    "eval_resting_covs_mean = [mean_riemann(i) for i in eval_resting_covs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_transform(covmats, reference):\n",
    "    \"\"\"\n",
    "    Apply the affine transformation:\n",
    "    C -> R^(-1/2) * C * R^(-1/2)\n",
    "    \"\"\"\n",
    "    ref_sqrt_inv = np.linalg.inv(scipy.linalg.sqrtm(reference))\n",
    "    return np.array([ref_sqrt_inv @ c @ ref_sqrt_inv for c in covmats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_transformed_train_covs = [affine_transform(train_active_covs[i], train_resting_covs_mean[i]) for i in range(len(train_active_covs))]\n",
    "affine_transformed_eval_covs = [affine_transform(eval_active_covs[i], eval_resting_covs_mean[i]) for i in range(len(eval_active_covs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDM - classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdm_classify(cov_train, y_train, cov_test, y_test):\n",
    "    \"\"\"\n",
    "    Minimum Distance to Mean (MDM) classification.\n",
    "\n",
    "    1) Compute Riemannian mean for each class\n",
    "    2) Assign each test trial to class with min Riemannian distance\n",
    "    \"\"\"\n",
    "    classes = np.unique(y_train)\n",
    "    means = {}\n",
    "    for c in classes:\n",
    "        means[c] = mean_riemann(cov_train[y_train == c])\n",
    "    \n",
    "    predictions = []\n",
    "    for test_cov in cov_test:\n",
    "        # Compute distance to each class mean\n",
    "        dists = {}\n",
    "        for c in classes:\n",
    "            dists[c] = distance_riemann(test_cov, means[c])\n",
    "        # Pick class with minimal distance\n",
    "        predictions.append(min(dists, key=dists.get))\n",
    "    \n",
    "    return np.mean(np.array(predictions) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7743055555555556\n",
      "0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "print(mdm_classify(train_active_covs[0], train_active_y[0], eval_active_covs[0], eval_active_y[0]))\n",
    "print(mdm_classify(affine_transformed_train_covs[0], train_active_y[0], affine_transformed_eval_covs[0], eval_active_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDM - untransformed\n",
      "Subject 1: 0.77\n",
      "Subject 2: 0.48\n",
      "Subject 3: 0.69\n",
      "Subject 4: 0.64\n",
      "Subject 5: 0.48\n",
      "Subject 6: 0.47\n",
      "Subject 7: 0.67\n",
      "Subject 8: 0.69\n",
      "Subject 9: 0.72\n"
     ]
    }
   ],
   "source": [
    "print(\"MDM - untransformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {mdm_classify(train_active_covs[i], train_active_y[i], eval_active_covs[i], eval_active_y[i]):.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDM - affine transformed\n",
      "Subject 1: 0.77\n",
      "Subject 2: 0.52\n",
      "Subject 3: 0.80\n",
      "Subject 4: 0.62\n",
      "Subject 5: 0.48\n",
      "Subject 6: 0.51\n",
      "Subject 7: 0.78\n",
      "Subject 8: 0.79\n",
      "Subject 9: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"MDM - affine transformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {mdm_classify(affine_transformed_train_covs[i], train_active_y[i], affine_transformed_eval_covs[i], eval_active_y[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_classify(cov_train, y_train, cov_test, y_test):\n",
    "    \"\"\"\n",
    "    Bayesian classification (eq. 8).\n",
    "    Each class: Riemannian mean = center of mass, plus MLE for sigma.\n",
    "\n",
    "    Classification rule:\n",
    "      arg min_k { log(zeta(sigma_k)) + dR^2(C, mean_k) / [2 * sigma_k^2] }\n",
    "    We do not need to compute log(zeta(sigma_k)) precisely for comparison,\n",
    "    but we include log(sigma_k) for approximate effect. \n",
    "    \"\"\"\n",
    "    classes = np.unique(y_train)\n",
    "    means = {}\n",
    "    sigmas = {}\n",
    "\n",
    "    # Estimate mean and sigma for each class\n",
    "    for c in classes:\n",
    "        cov_per_class = cov_train[y_train == c]\n",
    "        means[c] = mean_riemann(cov_per_class)\n",
    "        # Distances for MLE of sigma\n",
    "        dists = [distance_riemann(cov_, means[c]) for cov_ in cov_per_class]\n",
    "        sigmas[c] = np.sqrt(np.mean(np.square(dists))) if len(dists) > 0 else 1e-9\n",
    "\n",
    "    predictions = []\n",
    "    for test_cov in cov_test:\n",
    "        scores = {}\n",
    "        # We compare log(sigma_k) + d^2 / (2 sigma_k^2)\n",
    "        for c in classes:\n",
    "            d2 = distance_riemann(test_cov, means[c]) ** 2\n",
    "            # We skip the constant log(zeta(sigma_k)) because it doesn't change the arg min\n",
    "            # Use an approximate version: Score = log(sigma_k) + d2 / (2*sigma_k^2)\n",
    "            # The class with the smallest score is chosen\n",
    "            score = np.log(sigmas[c]) + (d2 / (2.0 * (sigmas[c] ** 2)))\n",
    "            scores[c] = score\n",
    "        predictions.append(min(scores, key=scores.get))\n",
    "    \n",
    "    return np.mean(np.array(predictions) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC - untransformed\n",
      "Subject 1: 0.76\n",
      "Subject 2: 0.46\n",
      "Subject 3: 0.69\n",
      "Subject 4: 0.60\n",
      "Subject 5: 0.37\n",
      "Subject 6: 0.49\n",
      "Subject 7: 0.65\n",
      "Subject 8: 0.72\n",
      "Subject 9: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(\"BC - untransformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {bayesian_classify(train_active_covs[i], train_active_y[i], eval_active_covs[i], eval_active_y[i]):.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC - affine transformed\n",
      "Subject 1: 0.78\n",
      "Subject 2: 0.51\n",
      "Subject 3: 0.80\n",
      "Subject 4: 0.62\n",
      "Subject 5: 0.48\n",
      "Subject 6: 0.51\n",
      "Subject 7: 0.78\n",
      "Subject 8: 0.78\n",
      "Subject 9: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"BC - affine transformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {bayesian_classify(affine_transformed_train_covs[i], train_active_y[i], affine_transformed_eval_covs[i], eval_active_y[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "from pyriemann.clustering import Kmeans\n",
    "from pyriemann.utils.distance import distance_riemann\n",
    "\n",
    "def log_zeta(sigma, m):\n",
    "    \"\"\"\n",
    "    Computes the log of the normalizing factor ζ(σ) for the Riemannian Gaussian.\n",
    "    For m = 2 an analytic expression is available.\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    if m == 2:\n",
    "        return 1.5 * np.log(2 * np.pi) + 2 * np.log(sigma + eps) + (sigma**2)/4 + np.log(scipy.special.erf(sigma/2) + eps)\n",
    "    else:\n",
    "        # For other dimensions, one might evaluate ζ(σ) numerically.\n",
    "        return 0.0\n",
    "\n",
    "def gmm_classify(cov_train, y_train, cov_test, y_test, n_components=2):\n",
    "    \"\"\"\n",
    "    Classify test SPD matrices using a Riemannian Gaussian mixture model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cov_train : ndarray, shape (n_train, m, m)\n",
    "        Training SPD matrices.\n",
    "    y_train : ndarray, shape (n_train,)\n",
    "        Training class labels.\n",
    "    cov_test : ndarray, shape (n_test, m, m)\n",
    "        Test SPD matrices.\n",
    "    y_test : ndarray, shape (n_test,)\n",
    "        True test labels.\n",
    "    n_components : int, default=2\n",
    "        Number of mixture components (clusters) per class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : ndarray, shape (n_test,)\n",
    "        Predicted labels for the test data.\n",
    "    \"\"\"\n",
    "    eps = 1e-10  # small constant to avoid division by 0 and log(0)\n",
    "    m = cov_train.shape[1]  # assuming SPD matrices of size m x m\n",
    "    cluster_params = []  # each entry is (class label, center, sigma, weight)\n",
    "\n",
    "    # Process each class separately.\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        idx = np.where(y_train == cls)[0]\n",
    "        mats = cov_train[idx]\n",
    "        # Cluster using pyriemann's Kmeans with the affine-invariant (Riemannian) metric.\n",
    "        kmeans = Kmeans(n_clusters=n_components, metric='riemann', init='random', tol=1e-6, max_iter=50)\n",
    "        labels = kmeans.fit_predict(mats)\n",
    "        # IMPORTANT: use the centroids() method (NOT the attribute \"centroids_\")\n",
    "        centers = kmeans.centroids()  \n",
    "\n",
    "        for k in range(n_components):\n",
    "            cluster_members = mats[labels == k]\n",
    "            if len(cluster_members) == 0:\n",
    "                continue\n",
    "            center = centers[k]\n",
    "            # Estimate dispersion sigma from the squared Riemannian distances.\n",
    "            dists_sq = np.array([distance_riemann(M, center, squared=True) for M in cluster_members])\n",
    "            sigma = np.sqrt(np.mean(dists_sq))\n",
    "            # Weight is the relative frequency of this cluster among all training matrices.\n",
    "            weight = len(cluster_members) / float(len(cov_train))\n",
    "            cluster_params.append((cls, center, sigma, weight))\n",
    "    \n",
    "    predictions = []\n",
    "    # Classify each test SPD matrix.\n",
    "    for Y in cov_test:\n",
    "        best_score = np.inf\n",
    "        best_class = None\n",
    "        for (cls, center, sigma, weight) in cluster_params:\n",
    "            # Calculate the squared Riemannian distance between Y and the cluster center.\n",
    "            dist_sq = distance_riemann(Y, center, squared=True)\n",
    "            # Compute a score that approximates the negative log-likelihood.\n",
    "            score = -np.log(weight + eps) + log_zeta(sigma, m) + dist_sq / (2 * (sigma**2 + eps))\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_class = cls\n",
    "        predictions.append(best_class)\n",
    "    \n",
    "    # return np.array(predictions)\n",
    "    \n",
    "    return np.mean(np.array(predictions) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM-4 - untransformed\n",
      "Subject 1: 0.49\n",
      "Subject 2: 0.31\n",
      "Subject 3: 0.52\n",
      "Subject 4: 0.25\n",
      "Subject 5: 0.25\n",
      "Subject 6: 0.28\n",
      "Subject 7: 0.65\n",
      "Subject 8: 0.43\n",
      "Subject 9: 0.48\n"
     ]
    }
   ],
   "source": [
    "print(\"GM-4 - untransformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {gmm_classify(train_active_covs[i], train_active_y[i], eval_active_covs[i], eval_active_y[i]):.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM-4 - affine transformed\n",
      "Subject 1: 0.48\n",
      "Subject 2: 0.33\n",
      "Subject 3: 0.49\n",
      "Subject 4: 0.27\n",
      "Subject 5: 0.25\n",
      "Subject 6: 0.30\n",
      "Subject 7: 0.58\n",
      "Subject 8: 0.41\n",
      "Subject 9: 0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"GM-4 - affine transformed\")\n",
    "for i in range(9):\n",
    "    print(f\"Subject {i+1}: {gmm_classify(affine_transformed_train_covs[i], train_active_y[i], affine_transformed_eval_covs[i], eval_active_y[i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
