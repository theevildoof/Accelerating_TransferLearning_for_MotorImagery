{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery, LeftRightImagery\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from mne.decoding import CSP\n",
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 1: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 2: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 3: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 4: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 5: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 6: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 7: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 8: Epoch data shape (144, 22, 501)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/contextlib.py:142: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['769', '770']\n",
      "Subject 9: Epoch data shape (144, 22, 501)\n",
      "Loaded data for 9 subjects.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Define a causal bandpass filter function using a Butterworth design.\n",
    "def causal_bandpass_filter(data, lowcut=8, highcut=30, fs=250, order=50):\n",
    "    nyq = 0.5 * fs\n",
    "    # Normalize the cutoff frequencies (Matlab's fir1 expects normalized cutoff frequencies\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Design the FIR filter. Note: order+1 coefficients are returned to match Matlab's fir1 which returns n+1 taps.\n",
    "    b = signal.firwin(order + 1, [low, high], window='hamming', pass_zero=False)\n",
    "    # Apply the filter causally using lfilter (this introduces a constant delay).\n",
    "    filtered_data = signal.lfilter(b, [1.0], data)\n",
    "    return filtered_data\n",
    "\n",
    "# Set the data directory where your GDF files are stored.\n",
    "data_dir = '/home/vishwa/eeg_tl/Recreating papers/BCICIV_2a'  # Replace with your actual path\n",
    "\n",
    "# Containers to hold processed data for all subjects.\n",
    "X = []         # List to hold numpy arrays with shape (n_trials, 22, 1001) per subject.\n",
    "y = []         # List to hold event labels per subject.\n",
    "metadata = []  # List to hold event metadata per subject.\n",
    "\n",
    "\n",
    "event_id = {'769': 769, '770': 770}\n",
    "# event_id = {'277': 277}\n",
    "# Epoch parameters:\n",
    "\n",
    "# With a sampling frequency of 250 Hz, 1001 samples equate to 1001/250 seconds.\n",
    "sfreq = 250\n",
    "tmin = 0       # Epoch start at cue onset.\n",
    "# Set tmax so that n_samples = (tmax-tmin)*sfreq + 1 = 1001, i.e. 4 seconds long.\n",
    "tmax = (1001 - 1) / sfreq  # This gives 4.0 seconds.\n",
    "\n",
    "# Loop over subjects. Assume files are named \"A01T.gdf\", \"A02T.gdf\", ..., \"A09T.gdf\".\n",
    "for subj in range(1, 10):\n",
    "    filename = os.path.join(data_dir, f'A{subj:02d}T.gdf')\n",
    "    \n",
    "    # Read the GDF file (using preload=True to load data into memory).\n",
    "    raw = mne.io.read_raw_gdf(filename, preload=True, verbose=False, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    # Retain only EEG channels (22 channels) and exclude EOG channels.\n",
    "    raw.pick_types(eeg=True, eog=False)\n",
    "    \n",
    "    # Extract events corresponding only to the four desired types.\n",
    "    events, _ = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    \n",
    "    # Create epochs from tmin to tmax.\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    # Get the epoch data (num_epochs x 22 channels x 1001 samples).\n",
    "    data = epochs.get_data()\n",
    "    \n",
    "    # Print the number of extracted epochs to verify\n",
    "    print(f\"Subject {subj}: Epoch data shape {data.shape}\")\n",
    "    \n",
    "    # Sampling frequency from raw.info (should be 250).\n",
    "    fs = int(raw.info['sfreq'])\n",
    "    # print(fs)\n",
    "    n_trials, n_channels, n_times = data.shape\n",
    "    filtered_data = np.empty_like(data)\n",
    "    \n",
    "    # Apply the causal bandpass filter channel‚Äêwise for each trial.\n",
    "    for trial in range(n_trials):\n",
    "        for ch in range(n_channels):\n",
    "            filtered_data[trial, ch, :] = causal_bandpass_filter(\n",
    "                data[trial, ch, :],\n",
    "                lowcut=8,    # Lower bound of sensorimotor rhythm.\n",
    "                highcut=30,  # Upper bound of sensorimotor rhythm.\n",
    "                fs=fs,\n",
    "                order=50     # Lower order for a smoother causal filter.\n",
    "            )\n",
    "    \n",
    "    # Append the processed data, labels, and event metadata.\n",
    "    X.append(filtered_data)\n",
    "    y.append(epochs.events[:, 2])  # The third column holds the event code.\n",
    "    metadata.append(epochs.events)\n",
    "\n",
    "print(\"Loaded data for\", len(X), \"subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 22, 501)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "print(y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aligned = []\n",
    "def EA(X):\n",
    "    covs = np.array([trial @ trial.T for trial in X])  # shape [n_trials, n_channels, n_channels]\n",
    "    mean_cov = np.mean(covs, axis=0)\n",
    "    # Eigen-decomposition of mean_cov\n",
    "    eigvals, eigvecs = np.linalg.eigh(mean_cov)\n",
    "    D_inv_sqrt = np.diag(eigvals**(-0.5))\n",
    "    R_inv_sqrt = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
    "\n",
    "    # Align each trial\n",
    "    xaligned = np.array([R_inv_sqrt @ trial for trial in X])\n",
    "    X_aligned.append(xaligned)\n",
    "\n",
    "for i in X:\n",
    "    EA(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 4\n",
    "csp = CSP(n_components=n_components, reg=None, log=True, norm_trace=False)\n",
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.17 (2.2e-16 eps * 22 dim * 3.4e+13  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=769 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=770 covariance using EMPIRICAL\n",
      "Done.\n",
      "Subject 1 Test Accuracy: 0.60\n",
      "Subject 2 Test Accuracy: 0.49\n",
      "Subject 3 Test Accuracy: 0.69\n",
      "Subject 4 Test Accuracy: 0.69\n",
      "Subject 5 Test Accuracy: 0.44\n",
      "Subject 6 Test Accuracy: 0.64\n",
      "Subject 7 Test Accuracy: 0.63\n",
      "Subject 8 Test Accuracy: 0.73\n",
      "Subject 9 Test Accuracy: 0.46\n",
      "\n",
      "Mean Cross-Validation Accuracy: 0.60 ¬± 0.10\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "# Assuming:\n",
    "# X_aligned = [subject1_data, ..., subject9_data] where each subject_data.shape = (288, 22, 1001)\n",
    "# y = [subject1_labels, ..., subject9_labels] where each labels.shape = (288,)\n",
    "\n",
    "for subj_idx in range(len(X_aligned)):\n",
    "    # print(subj_idx)\n",
    "    # Split data into train/test using leave-one-subject-out\n",
    "    X_test = X_aligned[subj_idx]\n",
    "    y_test = y[subj_idx]\n",
    "    \n",
    "    # Concatenate data from other subjects\n",
    "    X_train = np.concatenate([X_aligned[i] for i in range(len(X_aligned)) if i != subj_idx], axis=0)\n",
    "    y_train = np.concatenate([y[i] for i in range(len(y)) if i != subj_idx], axis=0)\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('CSP', CSP(n_components=n_components, reg=None, log=True, norm_trace=False)),\n",
    "        ('LDA', LinearDiscriminantAnalysis())\n",
    "    ])\n",
    "\n",
    "    # Fit and predict\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    accuracy = pipeline.score(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "for subj_idx in range(len(X_aligned)):\n",
    "    print(f\"Subject {subj_idx+1} Test Accuracy: {accuracies[subj_idx]:.2f}\")\n",
    "\n",
    "print(f\"\\nMean Cross-Validation Accuracy: {np.mean(accuracies):.2f} ¬± {np.std(accuracies):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
