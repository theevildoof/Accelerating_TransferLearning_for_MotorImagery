{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nested evaluation. This may take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BNCI2014-001-WithinSession:   0%|          | 0/1 [00:00<?, ?it/s]/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 24 events (all good), 4 – 8 s (baseline off), ~4.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 24 events (all good), 4 – 8 s (baseline off), ~4.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 24 events (all good), 4 – 8 s (baseline off), ~4.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 23 events (all good), 4 – 8 s (baseline off), ~3.9 MB, data loaded,\n",
      " 'left_hand': 11\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 24 events (all good), 4 – 8 s (baseline off), ~4.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "/home/vishwa/anaconda3/envs/eeg_proj/lib/python3.10/site-packages/moabb/datasets/preprocessing.py:279: UserWarning: warnEpochs <Epochs | 24 events (all good), 4 – 8 s (baseline off), ~4.1 MB, data loaded,\n",
      " 'left_hand': 12\n",
      " 'right_hand': 12>\n",
      "  warn(f\"warnEpochs {epochs}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hdf5_path provided, models will not be saved.\n",
      "No hdf5_path provided, models will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BNCI2014-001-WithinSession: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTS DataFrame ---\n",
      "       score      time  samples subject session  channels  n_sessions  \\\n",
      "0   0.750497  0.140671    140.0       1  0train        22           2   \n",
      "1   0.686447  0.144405    141.0       1   1test        22           2   \n",
      "2   0.617462  0.142078    140.0       1  0train        22           2   \n",
      "3   0.652606  0.144038    141.0       1   1test        22           2   \n",
      "4   0.645050  0.140228    141.0       2  0train        22           2   \n",
      "5   0.617865  0.142475    141.0       2   1test        22           2   \n",
      "6   0.704249  0.147674    141.0       3  0train        22           2   \n",
      "7   0.746792  0.152483    141.0       3   1test        22           2   \n",
      "8   0.600487  0.145376    141.0       4  0train        22           2   \n",
      "9   0.495882  0.137823    140.0       4   1test        22           2   \n",
      "10  0.751094  0.159001    141.0       5  0train        22           2   \n",
      "11  0.643359  0.148901    141.0       5   1test        22           2   \n",
      "12  0.573741  0.141534    142.0       6  0train        22           2   \n",
      "13  0.491774  0.143436    141.0       6   1test        22           2   \n",
      "14  0.799723  0.126422    141.0       7  0train        22           2   \n",
      "15  0.721732  0.143365    141.0       7   1test        22           2   \n",
      "16  0.767326  0.145871    141.0       8  0train        22           2   \n",
      "17  0.862543  0.138542    141.0       8   1test        22           2   \n",
      "18  0.699864  0.143775    142.0       9  0train        22           2   \n",
      "19  0.753103  0.143123    141.0       9   1test        22           2   \n",
      "\n",
      "         dataset     pipeline  \n",
      "0   BNCI2014-001  ACM_TangSVM  \n",
      "1   BNCI2014-001  ACM_TangSVM  \n",
      "2   BNCI2014-001      ACM_MDM  \n",
      "3   BNCI2014-001      ACM_MDM  \n",
      "4   BNCI2014-001      ACM_MDM  \n",
      "5   BNCI2014-001      ACM_MDM  \n",
      "6   BNCI2014-001      ACM_MDM  \n",
      "7   BNCI2014-001      ACM_MDM  \n",
      "8   BNCI2014-001      ACM_MDM  \n",
      "9   BNCI2014-001      ACM_MDM  \n",
      "10  BNCI2014-001      ACM_MDM  \n",
      "11  BNCI2014-001      ACM_MDM  \n",
      "12  BNCI2014-001      ACM_MDM  \n",
      "13  BNCI2014-001      ACM_MDM  \n",
      "14  BNCI2014-001      ACM_MDM  \n",
      "15  BNCI2014-001      ACM_MDM  \n",
      "16  BNCI2014-001      ACM_MDM  \n",
      "17  BNCI2014-001      ACM_MDM  \n",
      "18  BNCI2014-001      ACM_MDM  \n",
      "19  BNCI2014-001      ACM_MDM  \n",
      "\n",
      "--- MEAN AND STD OF SCORES ---\n",
      "\n",
      "ACM_MDM: 0.675 +/- 0.100\n",
      "ACM_TangSVM: 0.718 +/- 0.045\n",
      "\n",
      "Done. The results DataFrame contains details for each subject/session/fold.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Below is an example script to reproduce, in a simplified manner,\n",
    "the Motor Imagery benchmark results of the Augmented Covariance\n",
    "Method (ACM). It uses the MOABB library with the BNCI2014-001 dataset.\n",
    "\n",
    "Step-by-step notes (in comments) show how to handle:\n",
    "1) Loading the dataset and optionally filtering subjects.\n",
    "2) Configuring a MotorImagery paradigm with band-pass filtering.\n",
    "3) Building pipelines for classic approaches and ACM-based approaches.\n",
    "4) Setting up parameter grids for possible nested cross-validation.\n",
    "5) Running a WithinSessionEvaluation or CrossSessionEvaluation without\n",
    "   passing unsupported arguments (e.g., 'subj_list' is not recognized by\n",
    "   the latest MOABB code).\n",
    "6) Collecting and displaying the results.\n",
    "\n",
    "Make sure to install:\n",
    "    pip install moabb mne numpy scipy scikit-learn pyriemann\n",
    "as well as the code for the Augmented Covariance if needed.\n",
    "\n",
    "This script addresses a potential TypeError when creating a\n",
    "WithinSessionEvaluation or CrossSessionEvaluation, by not passing\n",
    "'args' that are no longer recognized ('subj_list'). Instead, if you\n",
    "want to restrict which subjects are processed, you can directly\n",
    "edit dataset.subject_list before running the evaluation.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# MOABB imports\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.evaluations import WithinSessionEvaluation, CrossSessionEvaluation\n",
    "\n",
    "# sklearn and pyriemann imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.classification import MDM, FgMDM\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.spatialfilters import CSP\n",
    "\n",
    "# If you are using the Augmented Covariance approach from a custom module,\n",
    "# import the class from wherever you've placed it. For illustration:\n",
    "try:\n",
    "    from moabb.pipelines.features import AugmentedDataset\n",
    "except ImportError:\n",
    "    # As a placeholder, define a dummy AugmentedDataset if not available.\n",
    "    # Replace with the actual AugmentedDataset class from the relevant source.\n",
    "    class AugmentedDataset:\n",
    "        def __init__(self, order=2, lag=1):\n",
    "            self.order = order\n",
    "            self.lag = lag\n",
    "        def fit_transform(self, X, y=None):\n",
    "            return X\n",
    "        def transform(self, X):\n",
    "            return X\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 1) Configure general parameters and bandpass\n",
    "###############################################################################\n",
    "\n",
    "# Filter parameters\n",
    "FMIN = 8.0\n",
    "FMAX = 35.0\n",
    "\n",
    "# Focus on 2-class MI, for instance left vs right hand\n",
    "EVENTS = [\"left_hand\", \"right_hand\"]  # 2-class\n",
    "\n",
    "# Time range of the epoch\n",
    "TMIN = 2.0\n",
    "TMAX = 6.0\n",
    "\n",
    "###############################################################################\n",
    "# 2) Load the dataset and (optionally) choose a subset of subjects\n",
    "###############################################################################\n",
    "dataset = BNCI2014_001()\n",
    "\n",
    "# Example: if you only want certain subjects, you can do:\n",
    "dataset.subject_list = [1]  # etc.\n",
    "# By default, uses dataset.subject_list as provided.\n",
    "\n",
    "# Create the MotorImagery paradigm\n",
    "paradigm = MotorImagery(\n",
    "    events=EVENTS,\n",
    "    n_classes=len(EVENTS),\n",
    "    fmin=FMIN,\n",
    "    fmax=FMAX,\n",
    "    tmin=TMIN,\n",
    "    tmax=TMAX\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 3) Build pipelines\n",
    "###############################################################################\n",
    "\n",
    "# Baseline pipeline 1: Covariance + Tangent Space + SVM\n",
    "cov_tang_svm = Pipeline([\n",
    "    (\"Cov\", Covariances(estimator=\"scm\")),\n",
    "    (\"Tangent\", TangentSpace(metric=\"riemann\")),\n",
    "    (\"SVM\", SVC(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "# # Baseline pipeline 2: CSP + LDA\n",
    "# csp_lda = Pipeline([\n",
    "#     (\"CSP\", CSP(nfilter=4, log=True)),\n",
    "#     (\"LDA\", LDA(solver=\"lsqr\", shrinkage=\"auto\"))\n",
    "# ])\n",
    "\n",
    "# # Baseline pipeline 3: FgMDM\n",
    "# fgmdm = Pipeline([\n",
    "#     (\"Cov\", Covariances(estimator=\"scm\")),\n",
    "#     (\"FgMDM\", FgMDM(metric=\"riemann\"))\n",
    "# ])\n",
    "\n",
    "# # Baseline pipeline 4: Cov + logistic regression\n",
    "# cov_lr = Pipeline([\n",
    "#     (\"Cov\", Covariances(estimator=\"scm\")),\n",
    "#     (\"Tangent\", TangentSpace(metric=\"riemann\")),\n",
    "#     (\"LR\", LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# ACM pipeline: Augmented Covariance + Tangent Space + SVM\n",
    "acm_tang_svm = Pipeline([\n",
    "    (\"ACM\", AugmentedDataset()),  # Use actual augmented transformation\n",
    "    (\"Cov\", Covariances(estimator=\"lwf\")),\n",
    "    (\"Tangent\", TangentSpace(metric=\"riemann\")),\n",
    "    (\"SVM\", SVC(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "# ACM pipeline: Augmented Covariance + MDM\n",
    "acm_mdm = Pipeline([\n",
    "    (\"ACM\", AugmentedDataset()),\n",
    "    (\"Cov\", Covariances(estimator=\"lwf\")),\n",
    "    (\"MDM\", MDM(metric=dict(mean='riemann', distance='riemann')))\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    # \"CovTangSVM\": cov_tang_svm,\n",
    "    # \"CSP_LDA\": csp_lda,\n",
    "    # \"FgMDM\": fgmdm,\n",
    "    # \"CovLR\": cov_lr,\n",
    "    \"ACM_TangSVM\": acm_tang_svm,\n",
    "    \"ACM_MDM\": acm_mdm\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 4) Parameter grid for (nested) cross-validation for hyperparam tuning\n",
    "###############################################################################\n",
    "param_grid = {\n",
    "    # \"CovTangSVM\": {\n",
    "    #     \"Tangent__metric\": [\"riemann\"],\n",
    "    #     \"SVM__C\": [0.5, 1, 1.5],\n",
    "    #     \"SVM__kernel\": [\"linear\", \"rbf\"]\n",
    "    # },\n",
    "    # \"CSP_LDA\": {\n",
    "    #     \"CSP__nfilter\": [2, 4, 6, 8],\n",
    "    # },\n",
    "    # \"FgMDM\": {},\n",
    "    # \"CovLR\": {\n",
    "    #     \"LR__C\": [0.01, 0.1, 1, 10]\n",
    "    # },\n",
    "    \"ACM_TangSVM\": {\n",
    "        \"ACM__order\": [1, 2, 3],\n",
    "        \"ACM__lag\": [1, 2],\n",
    "        \"SVM__C\": [0.5, 1, 1.5],\n",
    "        \"SVM__kernel\": [\"linear\", \"rbf\"]\n",
    "    },\n",
    "    \"ACM_MDM\": {\n",
    "        \"ACM__order\": [1, 2, 3],\n",
    "        \"ACM__lag\": [1, 2]\n",
    "    }\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 5) Run Within-Session or Cross-Session evaluation\n",
    "###############################################################################\n",
    "# Note: do not pass 'subj_list' here; it's not a recognized argument.\n",
    "# If you want to limit the subjects, filter dataset.subject_list beforehand.\n",
    "\n",
    "# Example: Within-Session\n",
    "# This performs k-fold CV (k=5 by default) within each session for each subject.\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=[dataset],\n",
    "    overwrite=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Alternatively, Cross-Session:\n",
    "# evaluation = CrossSessionEvaluation(\n",
    "#     paradigm=paradigm,\n",
    "#     datasets=[dataset],\n",
    "#     overwrite=False,\n",
    "#     random_state=42,\n",
    "#     n_jobs=1\n",
    "# )\n",
    "\n",
    "###############################################################################\n",
    "# 6) Execute the evaluation with nested cross-validation\n",
    "###############################################################################\n",
    "print(\"Starting nested evaluation. This may take some time...\")\n",
    "results = evaluation.process(\n",
    "    pipelines=pipelines,\n",
    "    # param_grid=param_grid, # triggers a nested CV using GridSearchCV\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 7) Print or save the results\n",
    "###############################################################################\n",
    "print(\"\\n--- RESULTS DataFrame ---\")\n",
    "print(results.head(20))\n",
    "\n",
    "mean_scores = results.groupby(['pipeline'])['score'].mean()\n",
    "std_scores = results.groupby(['pipeline'])['score'].std()\n",
    "\n",
    "print(\"\\n--- MEAN AND STD OF SCORES ---\\n\")\n",
    "for pipe in mean_scores.index:\n",
    "    print(f\"{pipe}: {mean_scores[pipe]:.3f} +/- {std_scores[pipe]:.3f}\")\n",
    "\n",
    "# Export if desired:\n",
    "# results.to_csv(\"motor_imagery_acm_results.csv\", index=False)\n",
    "\n",
    "print(\"\\nDone. The results DataFrame contains details for each subject/session/fold.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
